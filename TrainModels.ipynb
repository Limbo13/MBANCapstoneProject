{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ca9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import pandas as pd\n",
    "import csv\n",
    "from csv import writer\n",
    "from flaml import AutoML\n",
    "from flaml.ml import sklearn_metric_loss_score\n",
    "from flaml.data import get_output_from_log\n",
    "import joblib\n",
    "import os\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3093df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in data\n",
    "Corpus = pd.read_csv(r'<path to file>\\Full_Corpus.csv')\n",
    "#Convert blurb text to string datatype\n",
    "Corpus.text_final_blurb = Corpus.text_final_blurb.astype(str)\n",
    "#Drop unnecessary columns\n",
    "Corpus.drop(columns={'name','blurb','PercentileRank','Half','Twenties', 'Third','NumSuccess','NumFail'},axis=1,inplace=True,errors='ignore')\n",
    "print(Corpus.columns)\n",
    "#This is only run once to create the folder that will hold all of the models\n",
    "#os.makedirs(\"outputs\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5dedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start training models\n",
    "#Each of the four questions (both pre and post launch, will the project be successful, and how much money can we expect to make)\n",
    "#will have code run to produce a model for each combination of category and subcategory. \n",
    "#This is 156 combinations x 4 questions = 624 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c294794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to write to file\n",
    "#Note: this block is not written by me, it was taken from here:\n",
    "##https://thispointer.com/python-how-to-append-a-new-row-to-an-existing-csv-file/#:~:text=Append%20a%20dictionary%20as%20a%20row%20to%20an,the%20csv%20file%2C%20now%20close%20the%20file%20object%2C\n",
    "def append_list_as_row(file_name, list_of_elem):\n",
    "    # Open file in append mode\n",
    "    with open(file_name, 'a+', newline='') as write_obj:\n",
    "        # Create a writer object from csv module\n",
    "        csv_writer = writer(write_obj)\n",
    "        # Add contents of list as last row in the csv file\n",
    "        csv_writer.writerow(list_of_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d5c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting success, pre-launch\n",
    "#Set the predictor and outcome variables\n",
    "predictors = ['text_final_blurb','DaysDiffCreateLaunch', 'DaysDiffLaunchDeadline',\n",
    "       'CreatedDate_Month', 'CreatedDate_DayOfMonth', 'CreatedDate_Year', 'CreatedDate_DayOfWeek', \n",
    "       'DeadLineDate_Month', 'DeadLineDate_DayOfMonth', 'DeadLineDate_Year', 'DeadLineDate_DayOfWeek', \n",
    "        'LaunchedDate_Month', 'LaunchedDate_DayOfMonth', 'LaunchedDate_Year', 'LaunchedDate_DayOfWeek', \n",
    "        'NumPrevSuccess', 'NumPrevFail', 'goal_21']\n",
    "outcome = 'state_successful'\n",
    "\n",
    "#Counter variables\n",
    "NumResults = 0\n",
    "currGroup = 1\n",
    "\n",
    "#Check if there was a previous partial run\n",
    "prevRun = pd.DataFrame(columns=['Name', 'Estimator', 'Best Accuracy', 'Training Time','Best Config','Accuracy'])\n",
    "if os.path.exists(r'<path to file>\\PreLaunchSuccess.csv'):\n",
    "    prevRun = pd.read_csv(r'<path to file>\\PreLaunchSuccess.csv')\n",
    "    prevRun.Name = prevRun.Name.astype(str)\n",
    "\n",
    "#Counts the number of combinations so we know how many models will be produced\n",
    "#This will let us create a progress indicator used during training\n",
    "for name, group in Corpus.groupby(['CatID', 'SubCatID']):\n",
    "    NumResults += 1\n",
    "\n",
    "#Start the actual training\n",
    "for name, group in Corpus.groupby(['CatID', 'SubCatID']):\n",
    "    print(name)    \n",
    "    \n",
    "    if not (str(name) in prevRun['Name'].unique()):\n",
    "        #Temp dataframe used below\n",
    "        part_df = Corpus\n",
    "\n",
    "        #This block slices up the name variable for use in naming the model files\n",
    "        #Example: the name is (1.0,220), this turns it into [1.0,220]\n",
    "        nameSplit = str(name)\n",
    "        nameSplit = nameSplit.replace('(','')\n",
    "        nameSplit = nameSplit.replace(')','')\n",
    "        nameSplit = nameSplit.replace(' ','')\n",
    "        nameSplit = nameSplit.split(',')\n",
    "\n",
    "        #Grab the data associated with the predictor and outcome variables specified above\n",
    "        X = part_df[(part_df.CatID == name[0])&(part_df.SubCatID==name[1])][predictors]\n",
    "        y = part_df[(part_df.CatID == name[0])&(part_df.SubCatID==name[1])][outcome]\n",
    "\n",
    "        #This block runs tfidf on the blurb text and concatenates the resulting matrix to the X variable\n",
    "        vBlurb = TfidfVectorizer()\n",
    "        enc_blurb = vBlurb.fit_transform(X['text_final_blurb'])\n",
    "        df_enc_blurb = pd.DataFrame(enc_blurb.toarray(), columns=vBlurb.get_feature_names())\n",
    "        X.drop('text_final_blurb', axis=1, inplace=True)\n",
    "        df_enc_blurb.reset_index(drop=True,inplace=True)\n",
    "        X.reset_index(drop=True,inplace=True)\n",
    "        res = pd.concat([X, df_enc_blurb], axis=1)\n",
    "\n",
    "        #Splitting the dataset on an 80/20 split\n",
    "        X_train, X_test, Y_train, Y_test = model_selection.train_test_split(res,y,test_size=0.2)\n",
    "\n",
    "        #Using a try-except block in case a model doesn't train properly\n",
    "        try:\n",
    "            #Using AutoML and a beginning time budget of 10 minutes\n",
    "            #If it can't train a model in that time, it will rerun but add 5 minutes each time\n",
    "            #If it still can't find a model after ~39 minutes, it will fail into the except block\n",
    "            budgTime = 600\n",
    "            modelFound = False\n",
    "            while (modelFound == False) and (budgTime < 2361):\n",
    "                automl = AutoML()\n",
    "                settings = {\n",
    "                    \"time_budget\": budgTime,  # seconds\n",
    "                    \"metric\": 'accuracy', # metric used for the evaluation\n",
    "                    \"task\": 'classification', # type of the task\n",
    "                    \"early_stop\": True\n",
    "                }\n",
    "\n",
    "                automl.fit(X_train=X_train, y_train=Y_train, **settings)\n",
    "\n",
    "                if (automl.best_estimator is not None):\n",
    "                    modelFound = True\n",
    "\n",
    "                budgTime += 300\n",
    "\n",
    "            print('Best Machine Learning Algorithm:', automl.best_estimator)\n",
    "            print('Best hyperparmeter configuration:', automl.best_config)\n",
    "            print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "            print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))\n",
    "\n",
    "            #Make predictions\n",
    "            preds = automl.predict(X_test)\n",
    "\n",
    "            #Create a new list to store the values above and also the accuracy of the model as found with our predictions\n",
    "            #Then append to the ongoing dataframe\n",
    "            dfCalc = [name,automl.best_estimator,1-automl.best_loss,automl.best_config_train_time,automl.best_config,accuracy_score(Y_test, preds)]\n",
    "\n",
    "            #Export the model and vocabulary to separate files\n",
    "            #Vocabulary is needed for testing the blurb text entered by the end user of the tool\n",
    "            fileStr = \"presucc-\"+str(nameSplit[0])+\"-\"+str(nameSplit[1])\n",
    "            joblib.dump(value=automl, filename=\"outputs/\"+fileStr+\".pkl\")\n",
    "            joblib.dump(value=vBlurb, filename=\"outputs/\"+fileStr+\"-vocab.pkl\")\n",
    "\n",
    "            #Set the column names of the dataframe, print it to screen, then write the results to a file\n",
    "            if not os.path.exists(r'<path to file>\\PreLaunchSuccess.csv'):\n",
    "                dfCalc = [dfCalc]\n",
    "                df = pd.DataFrame(dfCalc,columns=['Name', 'Estimator', 'Best Accuracy', 'Training Time','Best Config','Accuracy'])\n",
    "                df.to_csv(r'<path to file>\\PreLaunchSuccess.csv',index=False)\n",
    "            else:\n",
    "                append_list_as_row(r'<path to file>\\PreLaunchSuccess.csv', dfCalc)            \n",
    "        except:\n",
    "            print(\"Failed\")\n",
    "        \n",
    "    #Print the progress for the person doing the training\n",
    "    print((currGroup/NumResults) * 100,\"% complete\")\n",
    "    currGroup += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43db4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting success, post-launch\n",
    "#Set the predictor and outcome variables\n",
    "predictors = ['text_final_blurb','DaysDiffCreateLaunch', 'DaysDiffLaunchDeadline',\n",
    "       'CreatedDate_Month', 'CreatedDate_DayOfMonth', 'CreatedDate_Year', 'CreatedDate_DayOfWeek', \n",
    "       'DeadLineDate_Month', 'DeadLineDate_DayOfMonth', 'DeadLineDate_Year', 'DeadLineDate_DayOfWeek', \n",
    "        'LaunchedDate_Month', 'LaunchedDate_DayOfMonth', 'LaunchedDate_Year', 'LaunchedDate_DayOfWeek', \n",
    "        'NumPrevSuccess', 'NumPrevFail', 'spotlight_True', 'staff_pick_True', 'goal_21']\n",
    "outcome = 'state_successful'\n",
    "\n",
    "#Counter variables\n",
    "NumResults = 0\n",
    "currGroup = 1\n",
    "\n",
    "#Check if there was a previous partial run\n",
    "prevRun = pd.DataFrame(columns=['Name', 'Estimator', 'Best Accuracy', 'Training Time','Best Config','Accuracy'])\n",
    "if os.path.exists(r'<path to file>\\PostLaunchSuccess.csv'):\n",
    "    prevRun = pd.read_csv(r'<path to file>\\PostLaunchSuccess.csv')\n",
    "    prevRun.Name = prevRun.Name.astype(str)\n",
    "\n",
    "#Counts the number of combinations so we know how many models will be produced\n",
    "#This will let us create a progress indicator used during training\n",
    "for name, group in Corpus.groupby(['CatID', 'SubCatID']):\n",
    "    NumResults += 1\n",
    "\n",
    "#Start the actual training\n",
    "for name, group in Corpus.groupby(['CatID', 'SubCatID']):\n",
    "    print(name)    \n",
    "    if not (str(name) in prevRun['Name'].unique()):\n",
    "        #Temp dataframe used below\n",
    "        part_df = Corpus\n",
    "\n",
    "        #This block slices up the name variable for use in naming the model files\n",
    "        #Example: the name is (1.0,220), this turns it into [1.0,220]\n",
    "        nameSplit = str(name)\n",
    "        nameSplit = nameSplit.replace('(','')\n",
    "        nameSplit = nameSplit.replace(')','')\n",
    "        nameSplit = nameSplit.replace(' ','')\n",
    "        nameSplit = nameSplit.split(',')\n",
    "\n",
    "        #Grab the data associated with the predictor and outcome variables specified above\n",
    "        X = part_df[(part_df.CatID == name[0])&(part_df.SubCatID==name[1])][predictors]\n",
    "        y = part_df[(part_df.CatID == name[0])&(part_df.SubCatID==name[1])][outcome]\n",
    "\n",
    "        #This block runs tfidf on the blurb text and concatenates the resulting matrix to the X variable\n",
    "        vBlurb = TfidfVectorizer()\n",
    "        enc_x = vBlurb.fit_transform(X['text_final_blurb'])\n",
    "        df_enc_x = pd.DataFrame(enc_x.toarray(), columns=vBlurb.get_feature_names())\n",
    "        X.drop('text_final_blurb', axis=1, inplace=True)\n",
    "        df_enc_x.reset_index(drop=True,inplace=True)\n",
    "        X.reset_index(drop=True,inplace=True)\n",
    "        res = pd.concat([X, df_enc_x], axis=1)\n",
    "\n",
    "        #Splitting the dataset on an 80/20 split\n",
    "        X_train, X_test, Y_train, Y_test = model_selection.train_test_split(res,y,test_size=0.2)\n",
    "\n",
    "        #Using a try-except block in case a model doesn't train properly\n",
    "        try:\n",
    "            #Using AutoML and a beginning time budget of 10 minutes\n",
    "            #If it can't train a model in that time, it will rerun but add 5 minutes each time\n",
    "            #If it still can't find a model after ~39 minutes, it will fail into the except block\n",
    "            budgTime = 600\n",
    "            modelFound = False\n",
    "            while (modelFound == False) and (budgTime < 1381):\n",
    "                automl = AutoML()\n",
    "                settings = {\n",
    "                    \"time_budget\": budgTime,  # seconds\n",
    "                    \"metric\": 'accuracy', # metric used for the evaluation\n",
    "                    \"task\": 'classification', # type of the task\n",
    "                    \"early_stop\": True\n",
    "                }\n",
    "\n",
    "                automl.fit(X_train=X_train, y_train=Y_train,\n",
    "                           **settings)\n",
    "\n",
    "                if (automl.best_estimator is not None):\n",
    "                    modelFound = True\n",
    "\n",
    "                budgTime += 300\n",
    "\n",
    "            print('Best Machine Learning Algorithm:', automl.best_estimator)\n",
    "            print('Best hyperparmeter configuration:', automl.best_config)\n",
    "            print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "            print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))\n",
    "\n",
    "            #Make predictions\n",
    "            preds = automl.predict(X_test)\n",
    "\n",
    "            #Create a new list to store the values above and also the accuracy of the model as found with our predictions\n",
    "            #Then append to the ongoing dataframe\n",
    "            dfCalc = [[name,automl.best_estimator,1-automl.best_loss,automl.best_config_train_time,automl.best_config,accuracy_score(Y_test, preds)]]\n",
    "\n",
    "            #Export the model and vocabulary to separate files\n",
    "            #Vocabulary is needed for testing the blurb text entered by the end user of the tool\n",
    "            fileStr = \"postsucc-\"+str(nameSplit[0])+\"-\"+str(nameSplit[1])\n",
    "            joblib.dump(value=automl, filename=\"outputs/\"+fileStr+\".pkl\")\n",
    "            joblib.dump(value=vBlurb, filename=\"outputs/\"+fileStr+\"-vocab.pkl\")\n",
    "\n",
    "            #Set the column names of the dataframe, print it to screen, then write the results to a file\n",
    "            if not os.path.exists(r'<path to file>\\PostLaunchSuccess.csv'):\n",
    "                dfCalc = [dfCalc]\n",
    "                df.columns = ['Name', 'Estimator', 'Best Accuracy', 'Training Time','Best Config','Accuracy']\n",
    "                df.to_csv(r'<path to file>\\PostLaunchSuccess.csv',index=False)\n",
    "            else:\n",
    "                append_list_as_row(r'<path to file>\\PostLaunchSuccess.csv', dfCalc)   \n",
    "        except:\n",
    "            print(\"Failed\")\n",
    "        \n",
    "    #Print the progress for the person doing the training\n",
    "    print((currGroup/NumResults) * 100,\"% complete\")\n",
    "    currGroup += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d072c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting final funding amount pre-launch\n",
    "#Set the predictor and outcome variables\n",
    "predictors = ['text_final_blurb','DaysDiffCreateLaunch', 'DaysDiffLaunchDeadline',\n",
    "       'CreatedDate_Month', 'CreatedDate_DayOfMonth', 'CreatedDate_Year', 'CreatedDate_DayOfWeek', \n",
    "       'DeadLineDate_Month', 'DeadLineDate_DayOfMonth', 'DeadLineDate_Year', 'DeadLineDate_DayOfWeek', \n",
    "        'LaunchedDate_Month', 'LaunchedDate_DayOfMonth', 'LaunchedDate_Year', 'LaunchedDate_DayOfWeek', \n",
    "        'NumPrevSuccess', 'NumPrevFail', 'goal_21']\n",
    "outcome = 'Tens'\n",
    "\n",
    "#Counter variables\n",
    "NumResults = 0\n",
    "currGroup = 1\n",
    "\n",
    "#Check if there was a previous partial run\n",
    "prevRun = pd.DataFrame(columns=['Name', 'Estimator', 'Best Accuracy', 'Training Time','Best Config','Accuracy'])\n",
    "if os.path.exists(r'<path to file>\\PreLaunchFunding.csv'):\n",
    "    prevRun = pd.read_csv(r'<path to file>\\PreLaunchFunding.csv')\n",
    "    prevRun.Name = prevRun.Name.astype(str)\n",
    "\n",
    "#Counts the number of combinations so we know how many models will be produced\n",
    "#This will let us create a progress indicator used during training\n",
    "for name, group in Corpus.groupby(['CatID', 'SubCatID']):\n",
    "    NumResults += 1\n",
    "\n",
    "#Start the actual training\n",
    "for name, group in Corpus.groupby(['CatID', 'SubCatID']):\n",
    "    print(name)    \n",
    "    if not (str(name) in prevRun['Name'].unique()):\n",
    "        #Temp dataframe used below\n",
    "        part_df = Corpus\n",
    "\n",
    "        #This block slices up the name variable for use in naming the model files\n",
    "        #Example: the name is (1.0,220), this turns it into [1.0,220]\n",
    "        nameSplit = str(name)\n",
    "        nameSplit = nameSplit.replace('(','')\n",
    "        nameSplit = nameSplit.replace(')','')\n",
    "        nameSplit = nameSplit.replace(' ','')\n",
    "        nameSplit = nameSplit.split(',')\n",
    "\n",
    "        #Grab the data associated with the predictor and outcome variables specified above\n",
    "        X = part_df[(part_df.CatID == name[0])&(part_df.SubCatID==name[1])][predictors]\n",
    "        y = part_df[(part_df.CatID == name[0])&(part_df.SubCatID==name[1])][outcome]\n",
    "\n",
    "        #This block runs tfidf on the blurb text and concatenates the resulting matrix to the X variable\n",
    "        vBlurb = TfidfVectorizer()\n",
    "        enc_x = vBlurb.fit_transform(X['text_final_blurb'])\n",
    "        df_enc_x = pd.DataFrame(enc_x.toarray(), columns=vBlurb.get_feature_names())\n",
    "        X.drop('text_final_blurb', axis=1, inplace=True)\n",
    "        df_enc_x.reset_index(drop=True,inplace=True)\n",
    "        X.reset_index(drop=True,inplace=True)\n",
    "        res = pd.concat([X, df_enc_x], axis=1)\n",
    "\n",
    "        #Splitting the dataset on an 80/20 split\n",
    "        X_train, X_test, Y_train, Y_test = model_selection.train_test_split(res,y,test_size=0.2)\n",
    "\n",
    "        #Using a try-except block in case a model doesn't train properly\n",
    "        try:\n",
    "            #Using AutoML and a beginning time budget of 10 minutes\n",
    "            #If it can't train a model in that time, it will rerun but add 5 minutes each time\n",
    "            #If it still can't find a model after ~39 minutes, it will fail into the except block\n",
    "            budgTime = 600\n",
    "            modelFound = False\n",
    "            while (modelFound == False) and (budgTime < 1381):\n",
    "                automl = AutoML()\n",
    "                settings = {\n",
    "                    \"time_budget\": budgTime,  # seconds\n",
    "                    \"metric\": 'accuracy', # metric used for the evaluation\n",
    "                    \"task\": 'classification', # type of the task\n",
    "                    \"early_stop\": True\n",
    "                }\n",
    "\n",
    "                automl.fit(X_train=X_train, y_train=Y_train,\n",
    "                           **settings)\n",
    "\n",
    "                if (automl.best_estimator is not None):\n",
    "                    modelFound = True\n",
    "\n",
    "                budgTime += 300\n",
    "\n",
    "            print('Best Machine Learning Algorithm:', automl.best_estimator)\n",
    "            print('Best hyperparmeter configuration:', automl.best_config)\n",
    "            print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "            print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))\n",
    "\n",
    "            #Make predictions; these predictions are then compared to the actual values\n",
    "            #The difference between the two are calculated, and written to a dataframe\n",
    "            #This dataframe is then written to the file\n",
    "            preds = automl.predict(X_test)\n",
    "            chkDF = pd.DataFrame()\n",
    "            realDF = pd.DataFrame(Y_test)\n",
    "            realDF.reset_index(drop=True,inplace=True)\n",
    "\n",
    "            rfDF = pd.DataFrame(preds)\n",
    "            rfDF.reset_index(drop=True,inplace=True)\n",
    "            chkDF = pd.concat([realDF, rfDF], axis=1)\n",
    "            chkDF.columns = ['Original','RF_Prediction']\n",
    "            chkDF['Difference'] = abs(chkDF['Original'] - chkDF['RF_Prediction'])\n",
    "            countVals = pd.DataFrame(chkDF['Difference'].value_counts())\n",
    "            countValsDF = countVals.reset_index()\n",
    "            countValsDF.columns = ['Diff','Num']\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0)]\n",
    "            calc0 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0)]\n",
    "            calc10 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0)]\n",
    "            calc20 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0)]\n",
    "            calc30 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0) | (countValsDF['Diff'] == 40.0)]\n",
    "            calc40 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0) | (countValsDF['Diff'] == 40.0) | (countValsDF['Diff'] == 50.0)]\n",
    "            calc50 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0) | (countValsDF['Diff'] == 40.0) | (countValsDF['Diff'] == 50.0) | (countValsDF['Diff'] == 60.0)]\n",
    "            calc60 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0) | (countValsDF['Diff'] == 40.0) | (countValsDF['Diff'] == 50.0) | (countValsDF['Diff'] == 60.0) | (countValsDF['Diff'] == 70.0)]\n",
    "            calc70 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0) | (countValsDF['Diff'] == 40.0) | (countValsDF['Diff'] == 50.0) | (countValsDF['Diff'] == 60.0) | (countValsDF['Diff'] == 70.0) | (countValsDF['Diff'] == 80.0)]\n",
    "            calc80 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0) | (countValsDF['Diff'] == 40.0) | (countValsDF['Diff'] == 50.0) | (countValsDF['Diff'] == 60.0) | (countValsDF['Diff'] == 70.0) | (countValsDF['Diff'] == 80.0) | (countValsDF['Diff'] == 90.0)]\n",
    "            calc90 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "\n",
    "            #Create a new list to store the values above and also the accuracy of the model as found with our predictions\n",
    "            #Then append to the ongoing dataframe\n",
    "            dfCalc = [[name,automl.best_estimator,1-automl.best_loss,automl.best_config_train_time,automl.best_config,calc0,calc10,calc20,calc30,calc40,calc50,calc60,calc70,calc80,calc90]]\n",
    "\n",
    "            #Export the model and vocabulary to separate files\n",
    "            #Vocabulary is needed for testing the blurb text entered by the end user of the tool\n",
    "            fileStr = \"prefund-\"+str(nameSplit[0])+\"-\"+str(nameSplit[1])\n",
    "            joblib.dump(value=automl, filename=\"outputs/\"+fileStr+\".pkl\")\n",
    "            joblib.dump(value=vBlurb, filename=\"outputs/\"+fileStr+\"-vocab.pkl\")\n",
    "\n",
    "            #Set the column names of the dataframe, print it to screen, then write the results to a file\n",
    "            if not os.path.exists(r'<path to file>\\PreLaunchFunding.csv'):\n",
    "                dfCalc = [dfCalc]\n",
    "                df = pd.DataFrame(dfCalc,columns = ['Name', 'Estimator', 'Best Accuracy', 'Training Time','Best Config','0', '10', '20','30','40','50','60','70','80','90'])\n",
    "                df.to_csv(r'<path to file>\\PreLaunchFunding.csv',index=False)\n",
    "            else:\n",
    "                append_list_as_row(r'<path to file>\\PreLaunchFunding.csv', dfCalc)     \n",
    "        except:\n",
    "            print(\"Failed\")\n",
    "        \n",
    "    #Print the progress for the person doing the training\n",
    "    print((currGroup/NumResults) * 100,\"% complete\")\n",
    "    currGroup += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04efd6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting final funding amount post-launch\n",
    "#Set the predictor and outcome variables\n",
    "predictors = ['text_final_blurb','DaysDiffCreateLaunch', 'DaysDiffLaunchDeadline',\n",
    "       'CreatedDate_Month', 'CreatedDate_DayOfMonth', 'CreatedDate_Year', 'CreatedDate_DayOfWeek', \n",
    "       'DeadLineDate_Month', 'DeadLineDate_DayOfMonth', 'DeadLineDate_Year', 'DeadLineDate_DayOfWeek', \n",
    "        'LaunchedDate_Month', 'LaunchedDate_DayOfMonth', 'LaunchedDate_Year', 'LaunchedDate_DayOfWeek', \n",
    "        'NumPrevSuccess', 'NumPrevFail', 'spotlight_True', 'staff_pick_True', 'goal_21']\n",
    "outcome = 'Tens'\n",
    "\n",
    "#Counter variables\n",
    "NumResults = 0\n",
    "currGroup = 1\n",
    "\n",
    "#Check if there was a previous partial run\n",
    "prevRun = pd.DataFrame(columns=['Name', 'Estimator', 'Best Accuracy', 'Training Time','Best Config','Accuracy'])\n",
    "if os.path.exists(r'<path to file>\\PostLaunchFunding.csv'):\n",
    "    prevRun = pd.read_csv(r'<path to file>\\PostLaunchFunding.csv')\n",
    "    prevRun.Name = prevRun.Name.astype(str)\n",
    "\n",
    "#Counts the number of combinations so we know how many models will be produced\n",
    "#This will let us create a progress indicator used during training\n",
    "for name, group in Corpus.groupby(['CatID', 'SubCatID']):\n",
    "    NumResults += 1\n",
    "\n",
    "#Start the actual training\n",
    "for name, group in Corpus.groupby(['CatID', 'SubCatID']):\n",
    "    print(name)    \n",
    "    \n",
    "    if not (str(name) in prevRun['Name'].unique()):\n",
    "        #Temp dataframe used below\n",
    "        part_df = Corpus\n",
    "\n",
    "        #This block slices up the name variable for use in naming the model files\n",
    "        #Example: the name is (1.0,220), this turns it into [1.0,220]\n",
    "        nameSplit = str(name)\n",
    "        nameSplit = nameSplit.replace('(','')\n",
    "        nameSplit = nameSplit.replace(')','')\n",
    "        nameSplit = nameSplit.replace(' ','')\n",
    "        nameSplit = nameSplit.split(',')\n",
    "\n",
    "        #Grab the data associated with the predictor and outcome variables specified above\n",
    "        X = part_df[(part_df.CatID == name[0])&(part_df.SubCatID==name[1])][predictors]\n",
    "        y = part_df[(part_df.CatID == name[0])&(part_df.SubCatID==name[1])][outcome]\n",
    "\n",
    "        #This block runs tfidf on the blurb text and concatenates the resulting matrix to the X variable\n",
    "        vBlurb = TfidfVectorizer()\n",
    "        enc_x = vBlurb.fit_transform(X['text_final_blurb'])\n",
    "        df_enc_x = pd.DataFrame(enc_x.toarray(), columns=vBlurb.get_feature_names())\n",
    "        X.drop('text_final_blurb', axis=1, inplace=True)\n",
    "        df_enc_x.reset_index(drop=True,inplace=True)\n",
    "        X.reset_index(drop=True,inplace=True)\n",
    "        res = pd.concat([X, df_enc_x], axis=1)\n",
    "        v = TfidfVectorizer()\n",
    "\n",
    "        #Splitting the dataset on an 80/20 split\n",
    "        X_train, X_test, Y_train, Y_test = model_selection.train_test_split(res,y,test_size=0.2)\n",
    "\n",
    "        #Using a try-except block in case a model doesn't train properly\n",
    "        try:\n",
    "            #Using AutoML and a beginning time budget of 10 minutes\n",
    "            #If it can't train a model in that time, it will rerun but add 5 minutes each time\n",
    "            #If it still can't find a model after ~39 minutes, it will fail into the except block\n",
    "            budgTime = 600\n",
    "            modelFound = False\n",
    "            while (modelFound == False) and (budgTime < 1381):\n",
    "                automl = AutoML()\n",
    "                settings = {\n",
    "                    \"time_budget\": budgTime,  # seconds\n",
    "                    \"metric\": 'accuracy', # metric used for the evaluation\n",
    "                    \"task\": 'classification', # type of the task\n",
    "                    \"early_stop\": True\n",
    "                }\n",
    "\n",
    "                automl.fit(X_train=X_train, y_train=Y_train,\n",
    "                           **settings)\n",
    "\n",
    "                if (automl.best_estimator is not None):\n",
    "                    modelFound = True\n",
    "\n",
    "                budgTime += 300\n",
    "\n",
    "            print('Best Machine Learning Algorithm:', automl.best_estimator)\n",
    "            print('Best hyperparmeter configuration:', automl.best_config)\n",
    "            print('Best accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
    "            print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))\n",
    "\n",
    "            #Make predictions; these predictions are then compared to the actual values\n",
    "            #The difference between the two are calculated, and written to a dataframe\n",
    "            #This dataframe is then written to the file\n",
    "            preds = automl.predict(X_test)\n",
    "            chkDF = pd.DataFrame()\n",
    "            realDF = pd.DataFrame(Y_test)\n",
    "            realDF.reset_index(drop=True,inplace=True)\n",
    "\n",
    "            rfDF = pd.DataFrame(preds)\n",
    "            rfDF.reset_index(drop=True,inplace=True)\n",
    "            chkDF = pd.concat([realDF, rfDF], axis=1)\n",
    "            chkDF.columns = ['Original','RF_Prediction']\n",
    "            chkDF['Difference'] = abs(chkDF['Original'] - chkDF['RF_Prediction'])\n",
    "            #print(chkDF['Difference'].value_counts())\n",
    "            countVals = pd.DataFrame(chkDF['Difference'].value_counts())\n",
    "            countValsDF = countVals.reset_index()\n",
    "            countValsDF.columns = ['Diff','Num']\n",
    "            #print(countValsDF[countValsDF['Diff'] == 0.0])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0)]\n",
    "            calc0 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0)]\n",
    "            calc10 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0)]\n",
    "            calc20 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0)]\n",
    "            calc30 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0) | (countValsDF['Diff'] == 40.0)]\n",
    "            calc40 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0) | (countValsDF['Diff'] == 40.0) | (countValsDF['Diff'] == 50.0)]\n",
    "            calc50 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0) | (countValsDF['Diff'] == 40.0) | (countValsDF['Diff'] == 50.0) | (countValsDF['Diff'] == 60.0)]\n",
    "            calc60 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0) | (countValsDF['Diff'] == 40.0) | (countValsDF['Diff'] == 50.0) | (countValsDF['Diff'] == 60.0) | (countValsDF['Diff'] == 70.0)]\n",
    "            calc70 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0) | (countValsDF['Diff'] == 40.0) | (countValsDF['Diff'] == 50.0) | (countValsDF['Diff'] == 60.0) | (countValsDF['Diff'] == 70.0) | (countValsDF['Diff'] == 80.0)]\n",
    "            calc80 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "            calcDF = countValsDF[(countValsDF['Diff'] == 0.0) | (countValsDF['Diff'] == 10.0) | (countValsDF['Diff'] == 20.0) | (countValsDF['Diff'] == 30.0) | (countValsDF['Diff'] == 40.0) | (countValsDF['Diff'] == 50.0) | (countValsDF['Diff'] == 60.0) | (countValsDF['Diff'] == 70.0) | (countValsDF['Diff'] == 80.0) | (countValsDF['Diff'] == 90.0)]\n",
    "            calc90 = calcDF['Num'].sum()/sum(countValsDF['Num'])\n",
    "\n",
    "            #Create a new list to store the values above and also the accuracy of the model as found with our predictions\n",
    "            #Then append to the ongoing dataframe\n",
    "            dfCalc = [[name,automl.best_estimator,1-automl.best_loss,automl.best_config_train_time,automl.best_config,calc0,calc10,calc20,calc30,calc40,calc50,calc60,calc70,calc80,calc90]]\n",
    "\n",
    "            #Export the model and vocabulary to separate files\n",
    "            #Vocabulary is needed for testing the blurb text entered by the end user of the tool\n",
    "            fileStr = \"postfund-\"+str(nameSplit[0])+\"-\"+str(nameSplit[1])\n",
    "            joblib.dump(value=automl, filename=\"outputs/\"+fileStr+\".pkl\")\n",
    "            joblib.dump(value=vBlurb, filename=\"outputs/\"+fileStr+\"-vocab.pkl\")\n",
    "\n",
    "            #Set the column names of the dataframe, print it to screen, then write the results to a file\n",
    "            if not os.path.exists(r'<path to file>\\PostLaunchFunding.csv'):\n",
    "                dfCalc = [dfCalc]\n",
    "                df = pd.DataFrame(dfCalc,columns = ['Name', 'Estimator', 'Best Accuracy', 'Training Time','Best Config','0', '10', '20','30','40','50','60','70','80','90'])\n",
    "                df.to_csv(r'<path to file>\\PostLaunchFunding.csv',index=False)\n",
    "            else:\n",
    "                append_list_as_row(r'<path to file>\\PostLaunchFunding.csv', dfCalc)     \n",
    "        except:\n",
    "            print(\"Failed\")\n",
    "        \n",
    "    #Print the progress for the person doing the training\n",
    "    print((currGroup/NumResults) * 100,\"% complete\")\n",
    "    currGroup += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
