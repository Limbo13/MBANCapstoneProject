{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cd26a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull in a full month\n",
    "kick_df = pd.concat(map(pd.read_csv, glob.glob(os.path.join( r'<path to file>\\2021\\May', 'kickstarter*.csv'))), ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd18956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns I know I won't use for either question (successful or not and how successful)\n",
    "kick_df.drop(columns={'is_starrable','is_starred','is_backing','friends','converted_pledged_amount','country_displayable_name','currency','currency_symbol','currency_trailing_code','current_currency','fx_rate','location','permissions','photo','profile','slug','source_url','state_changed_at','static_usd_rate','urls','usd_exchange_rate','usd_type'},axis=1,inplace=True,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533214ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop project that are canceled or live\n",
    "kick_df = kick_df.drop(kick_df[(kick_df['state'] != 'successful') & (kick_df['state'] != 'failed')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b27d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all dataset for 2016-2020\n",
    "months = {0:'Jan',1:'Feb',2:'Mar',3:'Apr',4:'May',5:'Jun',6:'Jul',7:'Aug',8:'Sep',9:'Oct',10:'Nov',11:'Dec'}\n",
    "years = {0:'2016',1:'2017',2:'2018',3:'2019',4:'2020',5:'2021'}\n",
    "\n",
    "for x in range(5,-1,-1):\n",
    "    if x == 5:\n",
    "        y = 3\n",
    "    else:\n",
    "        y = 11\n",
    "    for i in range(y,-1,-1):\n",
    "        print(months[i]+\" \"+years[x])\n",
    "        try:\n",
    "            temp_df = pd.concat(map(pd.read_csv, glob.glob(os.path.join('<path to file>\\\\'+years[x]+'\\\\'+months[i], 'kickstarter*.csv'))), ignore_index= True)\n",
    "            temp_df.drop(columns={'is_starrable','is_starred','is_backing','friends','converted_pledged_amount','country_displayable_name','currency','currency_symbol','currency_trailing_code','current_currency','fx_rate','location','permissions','photo','profile','slug','source_url','state_changed_at','static_usd_rate','urls','usd_exchange_rate','usd_type','unread_messages_count_x', 'unseen_activity_count_x','unread_messages_count_y', 'unseen_activity_count_y', 'unseen_activity_count','unread_messages_count'},axis=1,inplace=True,errors='ignore')\n",
    "            df3 = pd.merge(kick_df,temp_df,how='outer',indicator='Exist',on='id')\n",
    "            df3.rename(columns={'blurb_y':'blurb','name_y':'name','pledged_y':'pledged','backers_count_y':'backers_count', 'category_y':'category', 'country_y':'country','created_at_y':'created_at', 'creator_y':'creator', 'deadline_y':'deadline', 'disable_communication_y':'disable_communication','goal_y':'goal', 'launched_at_y':'launched_at', 'spotlight_y':'spotlight', 'staff_pick_y':'staff_pick', 'state_y':'state','usd_pledged_y':'usd_pledged'},inplace=True)\n",
    "            kick_df = kick_df.merge(df3.loc[df3['Exist'] == 'right_only'],how='outer')\n",
    "            kick_df.drop(columns={'blurb_x','name_x','pledged_x','backers_count_x', 'category_x', 'country_x', 'created_at_x','creator_x', 'deadline_x', 'disable_communication_x', 'goal_x','launched_at_x', 'spotlight_x', 'staff_pick_x', 'state_x','usd_pledged_x','Exist'},axis=1,inplace=True,errors='ignore')\n",
    "            kick_df = kick_df.drop(kick_df[(kick_df['state'] != 'successful') & (kick_df['state'] != 'failed')].index)\n",
    "            kick_df.drop_duplicates(['id'],keep='first',inplace=True)\n",
    "        except IOError:\n",
    "            print(\"File not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa3d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull in another month, which will be appended to the first month (only rows that don't match)\n",
    "temp_df = pd.concat(map(pd.read_csv, glob.glob(os.path.join( r'<path to file>\\2016\\Jan', 'kickstarter*.csv'))), ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4565838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns I know I won't use for either question (successful or not and how successful)\n",
    "temp_df.drop(columns={'is_starrable','is_starred','is_backing','friends','converted_pledged_amount','country_displayable_name','currency','currency_symbol','currency_trailing_code','current_currency','fx_rate','location','permissions','photo','profile','slug','source_url','state_changed_at','static_usd_rate','urls','usd_exchange_rate','usd_type'},axis=1,inplace=True,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3497a090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only include projects that were either successful or failed\n",
    "temp_df = temp_df.drop(temp_df[(kick_df['state'] != 'successful') & (temp_df['state'] != 'failed')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c7cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final merge on Jan 2016 data\n",
    "df3 = pd.merge(kick_df,temp_df,how='outer',indicator='Exist',on='id')\n",
    "df3.rename(columns={'blurb_y':'blurb','name_y':'name','pledged_y':'pledged','backers_count_y':'backers_count', 'category_y':'category', 'country_y':'country','created_at_y':'created_at', 'creator_y':'creator', 'deadline_y':'deadline', 'disable_communication_y':'disable_communication','goal_y':'goal', 'launched_at_y':'launched_at', 'spotlight_y':'spotlight', 'staff_pick_y':'staff_pick', 'state_y':'state','usd_pledged_y':'usd_pledged'},inplace=True)\n",
    "kick_df = kick_df.merge(df3.loc[df3['Exist'] == 'right_only'],how='outer')\n",
    "kick_df.drop(columns={'blurb_x','name_x','pledged_x','backers_count_x', 'category_x', 'country_x', 'created_at_x','creator_x', 'deadline_x', 'disable_communication_x', 'goal_x','launched_at_x', 'spotlight_x', 'staff_pick_x', 'state_x','usd_pledged_x','Exist'},axis=1,inplace=True,errors='ignore')\n",
    "kick_df = kick_df.drop(kick_df[(kick_df['state'] != 'successful') & (kick_df['state'] != 'failed')].index)\n",
    "kick_df.drop_duplicates(['id'],keep='first',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9111db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expand and manipulate creator column\n",
    "colList_expanded = kick_df['creator'].str.split(',', expand=True)\n",
    "colList_expanded.columns = ['creator'+str(i) for i in colList_expanded.columns]\n",
    "kick_df = pd.concat([kick_df,colList_expanded], axis=1)\n",
    "kick_df['CreatorID'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1284e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in the CreatorID\n",
    "for index,row in kick_df.iterrows():  \n",
    "    print(index)\n",
    "    for i in range(16):\n",
    "        string = kick_df.loc[index,'creator'+str(i)]\n",
    "        if (string[2:4] == 'id'):\n",
    "            kick_df.loc[index,'CreatorID'] = string[6:]\n",
    "            break\n",
    "        elif (string[1:3] == 'id'):\n",
    "            kick_df.loc[index,'CreatorID'] = string[5:]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace51b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop remaining columns\n",
    "kick_df.drop(columns={'last_update_published_at','unread_messages_count','unseen_activity_count','unread_messages_count_x','unseen_activity_count_x','unread_messages_count_y','unseen_activity_count_y','last_update_published_at_x','last_update_published_at_y', 'creator', 'creator0', 'creator1', 'creator2','creator3', 'creator4', 'creator5', 'creator6', 'creator7', 'creator8','creator9', 'creator10', 'creator11', 'creator12', 'creator13','creator14', 'creator15',},axis=1,inplace=True,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is now clean, moving forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expand and manipulate category column\n",
    "#Part 1\n",
    "kick_df['CatID'] = ''\n",
    "colList_expanded = kick_df['category'].str.split(',', expand=True)\n",
    "colList_expanded.columns = ['category'+str(i) for i in colList_expanded.columns]\n",
    "kick_df = pd.concat([kick_df,colList_expanded], axis=1)\n",
    "kick_df = kick_df.replace('\"','',regex=True)\n",
    "kick_df = kick_df.replace('{id:','',regex=True)\n",
    "for index,row in kick_df.iterrows():       \n",
    "    for element in row:\n",
    "        if type(element) == str:\n",
    "            if element.startswith('parent_id:'):\n",
    "                kick_df.loc[index,'CatID'] = element\n",
    "kick_df = kick_df.replace('parent_id:','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bacfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2\n",
    "kick_df['SubCatID'] = ''\n",
    "for index,row in kick_df.iterrows():  \n",
    "    print(index)\n",
    "    for i in range(9):\n",
    "        string = kick_df.loc[index,'category'+str(i)]\n",
    "        if string is not None:\n",
    "            if (string[0:2] == 'id'):\n",
    "                kick_df.loc[index,'SubCatID'] = string[3:]\n",
    "                break\n",
    "        kick_df.loc[index,'SubCatID'] = kick_df.loc[index,'category0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a34aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary category columns\n",
    "kick_df.drop(columns={'category','category0','category1','category2','category3','category4','category5','category6','category7','category8'},axis=1,inplace=True,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceee532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unnecessary creator and other columns\n",
    "kick_df.drop(columns={'disable_communication'},axis=1,inplace=True,errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58746b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working with dates\n",
    "#Part 1: Convert date columns from Unix epoch time\n",
    "kick_df['CreatedDate'] = pd.to_datetime(kick_df['created_at'],unit='s')\n",
    "kick_df['DeadLineDate'] = pd.to_datetime(kick_df['deadline'],unit='s')\n",
    "kick_df['LaunchedDate'] = pd.to_datetime(kick_df['launched_at'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84547474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2: Create columns that show difference between dates and drop original columns\n",
    "kick_df['DaysDiffCreateLaunch'] = (kick_df['LaunchedDate'] - kick_df['CreatedDate']).dt.days\n",
    "kick_df['DaysDiffLaunchDeadline'] = (kick_df['DeadLineDate'] - kick_df['LaunchedDate']).dt.days\n",
    "kick_df.drop(columns={'created_at','deadline','launched_at'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4dd6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3: Create columns that separate out parts of dates\n",
    "#Note: Day of week start with Monday as zero\n",
    "#Tough to pull out the week in the month, pursue this if predictions not accurate\n",
    "#Could also try \"day of year\", but with a small number of years, this doesn't seem like a good idea\n",
    "kick_df['CreatedDate_Month'] = kick_df['CreatedDate'].dt.month\n",
    "kick_df['CreatedDate_DayOfMonth'] = kick_df['CreatedDate'].dt.day\n",
    "kick_df['CreatedDate_Year'] = kick_df['CreatedDate'].dt.year\n",
    "kick_df['CreatedDate_DayOfWeek'] = kick_df['CreatedDate'].dt.weekday\n",
    "\n",
    "kick_df['DeadLineDate_Month'] = kick_df['DeadLineDate'].dt.month\n",
    "kick_df['DeadLineDate_DayOfMonth'] = kick_df['DeadLineDate'].dt.day\n",
    "kick_df['DeadLineDate_Year'] = kick_df['DeadLineDate'].dt.year\n",
    "kick_df['DeadLineDate_DayOfWeek'] = kick_df['DeadLineDate'].dt.weekday\n",
    "\n",
    "kick_df['LaunchedDate_Month'] = kick_df['LaunchedDate'].dt.month\n",
    "kick_df['LaunchedDate_DayOfMonth'] = kick_df['LaunchedDate'].dt.day\n",
    "kick_df['LaunchedDate_Year'] = kick_df['LaunchedDate'].dt.year\n",
    "kick_df['LaunchedDate_DayOfWeek'] = kick_df['LaunchedDate'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026cef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kick_df['NumSuccess'] = 0\n",
    "kick_df['NumFail'] = 0\n",
    "kick_df['NumPrevSuccess'] = 0\n",
    "kick_df['NumPrevFail'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8c5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping rows with live as the status\n",
    "kick_df = kick_df[kick_df.state != 'live']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3529b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#New attempt for success/failure\n",
    "dictCreator = {}\n",
    "for index,row in kick_df.iterrows():\n",
    "    CreatorID = row['CreatorID']\n",
    "    print(CreatorID)\n",
    "    \n",
    "    if CreatorID not in dictCreator:    \n",
    "        dictCreator[CreatorID] = {}\n",
    "        dictCreator[CreatorID]['NumSuccess'] = 0\n",
    "        dictCreator[CreatorID]['NumFail'] = 0\n",
    "        \n",
    "    kick_df.loc[index,'NumPrevSuccess'] = dictCreator[CreatorID]['NumSuccess']\n",
    "    kick_df.loc[index,'NumPrevFail'] = dictCreator[CreatorID]['NumFail']\n",
    "                    \n",
    "    if row['state'] == 'successful':\n",
    "        dictCreator[CreatorID]['NumSuccess'] +=1\n",
    "    elif row['state'] == 'failed':\n",
    "        dictCreator[CreatorID]['NumFail'] += 1  \n",
    "        \n",
    "    kick_df.loc[index,'NumSuccess'] = dictCreator[CreatorID]['NumSuccess']\n",
    "    kick_df.loc[index,'NumFail'] = dictCreator[CreatorID]['NumFail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f176b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing to dummy variables\n",
    "kick_df = pd.get_dummies(kick_df,columns=['spotlight','staff_pick','state'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef49371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping state_failed\n",
    "kick_df.drop(columns={'state_failed'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final write to CSV\n",
    "kick_df.to_csv( r'<path to file>\\FinalFullDataset.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
